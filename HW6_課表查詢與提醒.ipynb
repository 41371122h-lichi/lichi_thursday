{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgCbk9DIuJdETxsUxvZwXO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/41371122h-lichi/lichi_thursday/blob/main/HW6_%E8%AA%B2%E8%A1%A8%E6%9F%A5%E8%A9%A2%E8%88%87%E6%8F%90%E9%86%92.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# èª²è¡¨æŸ¥è©¢èˆ‡æé†’ (ä½œæ¥­å…­)\n",
        "\n",
        "ä»¥ä¸‹æ˜¯æ­¤ç¨‹å¼å¯ä»¥ä½¿ç”¨çš„åŠŸèƒ½ï¼š\n",
        "\n",
        "1.   åŒ¯å…¥PDFä¸¦å°‡èª²è¡¨ä¸Šå‚³è‡³æŒ‡å®šçš„google sheet\n",
        "2.   è¼¸å…¥æœ¬é€±èª²ç¨‹çš„ä½œæ¥­/è¤‡ç¿’ç« ç¯€/å‚™è¨»\n",
        "1.   è¼¸å…¥ä¸‹é€±èª²ç¨‹çš„æ‡‰å¸¶ç”¨å“/é ç¿’ç« ç¯€/å‚™è¨»\n",
        "2.   è®“AIå°åŠ©æ‰‹æé†’ä½ è¦å¸¶çš„æ±è¥¿\n",
        "1.   è®“AIå°åŠ©æ‰‹æ¨è–¦çµ¦ä½ è·Ÿèª²ç¨‹æœ‰é—œçš„å½±ç‰‡å’Œæ–‡ç« å§\n",
        "\n",
        "p.s æˆ‘å€‘è¦ªæ„›çš„Geminié‚„ä¸å¤ªç©©å®šï¼Œè‹¥æ˜¯æœ‰æŠŠã€Œçµ±è¨ˆå­¸(ä¸€)ã€åˆ†ç‚ºã€Œçµ±è¨ˆå­¸ã€å’Œã€Œçµ±è¨ˆå­¸(ä¸€)ã€çš„æ™‚å€™ï¼Œå†è«‹å„ä½å¤šè«’è§£äº†~\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FMklz-9GAsl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-genai pytz gradio gspread pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Nvy1cqOiert",
        "outputId": "41a0809d-c35b-4923-e745-988143c6d22c"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.48.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (2025.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.12/dist-packages (6.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.11.10)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.121.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.4)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.49.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from gspread) (1.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, uuid, re, json\n",
        "import pandas as pd\n",
        "import pytz\n",
        "from datetime import datetime as dt_class, timedelta, date\n",
        "from dateutil.tz import gettz\n",
        "import gradio as gr\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "from google.colab import userdata\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "bw6Os-cwiMWi"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "    print(\"âœ… Google æœå‹™æˆæ¬Šå®Œæˆ\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Google æœå‹™æˆæ¬Šå¤±æ•—ï¼Œè«‹ç¢ºèª Colab èªè­‰ï¼š{e}\")\n",
        "    gc = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDqTgYO0iWCN",
        "outputId": "79e3606e-07b6-468e-d209-e2182c101d1c"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Google æœå‹™æˆæ¬Šå®Œæˆ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    api_key = userdata.get('gemini')\n",
        "    genai.configure(api_key=api_key)\n",
        "    model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "    print(f\"âœ… Gemini API é…ç½®å®Œæˆ\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Gemini API é…ç½®å¤±æ•—ã€‚è«‹æª¢æŸ¥ Colab Secrets ä¸­çš„ 'gemini' å¯†é‘°: {e}\")\n",
        "    model = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT2aoqw1ijc_",
        "outputId": "e4f45c81-2dd5-470d-e5ad-1150bbf65455"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Gemini API é…ç½®å®Œæˆ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SHEET_URL = \"https://docs.google.com/spreadsheets/d/1zfGFuyvL1T1WoeoUTHWMtlZH01K5AzcyoNDef0-ylxE/edit?usp=sharing\"\n",
        "WORKSHEET_NAME_CURRENT = \"æœ¬é€±èª²è¡¨\"\n",
        "WORKSHEET_NAME_NEXT = \"ä¸‹é€±èª²è¡¨\"\n",
        "TIMEZONE = \"Asia/Taipei\"\n",
        "TW_TZ = pytz.timezone(TIMEZONE)\n",
        "\n",
        "COLUMNS_CURRENT = [\"æ—¥æœŸ\",\"æ˜ŸæœŸ\",\"èª²ç¨‹åç¨±\",\"æ™‚é–“(èµ·)\",\"æ™‚é–“(è¿„)\",\"åœ°é»\",\"ä½œæ¥­\",\"è¤‡ç¿’ç« ç¯€\",\"å‚™è¨»\"]\n",
        "COLUMNS_NEXT    = [\"æ—¥æœŸ\",\"æ˜ŸæœŸ\",\"èª²ç¨‹åç¨±\",\"æ™‚é–“(èµ·)\",\"æ™‚é–“(è¿„)\",\"åœ°é»\",\"æ‡‰å¸¶ç”¨å“\",\"é ç¿’ç« ç¯€\",\"å‚™è¨»\"]\n",
        "COMMON_COLS = [\"æ—¥æœŸ\",\"æ˜ŸæœŸ\",\"èª²ç¨‹åç¨±\",\"æ™‚é–“(èµ·)\",\"æ™‚é–“(è¿„)\",\"åœ°é»\",\"å‚™è¨»\"]\n",
        "ALL_COLUMNS = list(set(COLUMNS_CURRENT + COLUMNS_NEXT))"
      ],
      "metadata": {
        "id": "v1JRcQCqimCA"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# æ—¥æœŸé‹ç®—\n",
        "today = dt_class.now(TW_TZ).date()\n",
        "current_week_start_date = today - timedelta(days=today.weekday())\n",
        "current_week_end_date = current_week_start_date + timedelta(days=6)\n",
        "next_week_start_date = current_week_start_date + timedelta(days=7)\n",
        "next_week_end_date = next_week_start_date + timedelta(days=6)\n",
        "\n",
        "START_DATE_CURRENT = current_week_start_date\n",
        "END_DATE_CURRENT = current_week_end_date\n",
        "START_DATE_NEXT = next_week_start_date\n",
        "END_DATE_NEXT = next_week_end_date\n",
        "\n",
        "# Gradio Dropdownçš„æ—¥æœŸé¸é …\n",
        "DATE_OPTIONS = {}\n",
        "def get_date_options():\n",
        "    date_options = {}\n",
        "    for i in range(7):\n",
        "        current_date = START_DATE_CURRENT + timedelta(days=i)\n",
        "        date_str = current_date.strftime(\"%Y-%m-%d\")\n",
        "        label = f\"æœ¬é€± {current_date.strftime('%Y-%m-%d')} ({['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'æ—¥'][i]})\"\n",
        "        date_options[label] = date_str\n",
        "\n",
        "    for i in range(7):\n",
        "        next_date = START_DATE_NEXT + timedelta(days=i)\n",
        "        date_str = next_date.strftime(\"%Y-%m-%d\")\n",
        "        label = f\"ä¸‹é€± {next_date.strftime('%Y-%m-%d')} ({['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'æ—¥'][i]})\"\n",
        "        date_options[label] = date_str\n",
        "    return date_options\n",
        "\n",
        "DATE_OPTIONS = get_date_options()"
      ],
      "metadata": {
        "id": "lhEpA7kDirPo"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# çµ±ä¸€è™•ç†æ—¥æœŸå’Œæ¬„ä½\n",
        "def standardize_df(df, expected_cols):\n",
        "    if df.empty: return pd.DataFrame()\n",
        "\n",
        "    TEXT_COLUMNS_TO_CLEAN = [\"ä½œæ¥­\", \"è¤‡ç¿’ç« ç¯€\", \"æ‡‰å¸¶ç”¨å“\", \"é ç¿’ç« ç¯€\", \"å‚™è¨»\"]\n",
        "\n",
        "    for col in ALL_COLUMNS:\n",
        "        if col not in df.columns:\n",
        "            df[col] = ''\n",
        "        elif col in TEXT_COLUMNS_TO_CLEAN:\n",
        "             df[col] = df[col].astype(str).replace({'nan': ''}).fillna('')\n",
        "\n",
        "    def ensure_datetime(s):\n",
        "        if not s: return pd.NaT\n",
        "        try:\n",
        "            s = str(s).strip().replace(\"/\", \"-\")\n",
        "\n",
        "            date_obj = pd.to_datetime(s, errors='coerce')\n",
        "\n",
        "            if pd.notna(date_obj):\n",
        "                return date_obj.date()\n",
        "            return pd.NaT\n",
        "        except Exception:\n",
        "            return pd.NaT\n",
        "\n",
        "    df[\"æ—¥æœŸ\"] = df[\"æ—¥æœŸ\"].apply(ensure_datetime)\n",
        "    df = df.dropna(subset=[\"æ—¥æœŸ\"])\n",
        "    return df[ALL_COLUMNS]\n",
        "\n",
        "# å¾ Sheets è¼‰å…¥æ•¸æ“š\n",
        "def load_sheet_to_df(worksheet_name):\n",
        "    try:\n",
        "        gsheets = gc.open_by_url(SHEET_URL)\n",
        "        sheets = gsheets.worksheet(worksheet_name).get_all_values()\n",
        "        df = pd.DataFrame(sheets[1:], columns=sheets[0])\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"è¼‰å…¥åˆ†é  {worksheet_name} å¤±æ•—: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# åˆå§‹è¼‰å…¥æ‰€æœ‰æ•¸æ“š\n",
        "def initial_data_load():\n",
        "    df_current = standardize_df(load_sheet_to_df(WORKSHEET_NAME_CURRENT), COLUMNS_CURRENT)\n",
        "    df_next = standardize_df(load_sheet_to_df(WORKSHEET_NAME_NEXT), COLUMNS_NEXT)\n",
        "    df_all = pd.concat([df_current, df_next], ignore_index=True)\n",
        "    return df_all, df_current, df_next\n",
        "\n",
        "# æå–èª²è¡¨ä¸»å‡½å¼\n",
        "def process_week_with_gemini(start_date, end_date, worksheet_name, column_structure, pdf_path):\n",
        "    if model is None or gc is None:\n",
        "        return pd.DataFrame(columns=column_structure), f\"âŒ ç’°å¢ƒéŒ¯èª¤ï¼šGemini æˆ– Google Sheets æœå‹™æœªé…ç½®/æˆæ¬Šã€‚\"\n",
        "\n",
        "    print(f\"\\n--- âš™ï¸ è™•ç† {worksheet_name} ({start_date} ~ {end_date}) ---\")\n",
        "\n",
        "    start_date_str = start_date.strftime(\"%Y/%m/%d\")\n",
        "    end_date_str = end_date.strftime(\"%Y/%m/%d\")\n",
        "\n",
        "    helper_cols = \",\".join([c for c in column_structure if c not in COMMON_COLS])\n",
        "    csv_header = \",\".join(column_structure)\n",
        "\n",
        "    prompt_text = f\"\"\"\n",
        "    ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è³‡æ–™æ“·å–åŠ©ç†ï¼Œä»»å‹™æ˜¯**å¿ å¯¦åœ°**å¾æˆ‘ä¸Šå‚³çš„ PDF èª²è¡¨æª”æ¡ˆä¸­æå–è³‡è¨Šã€‚\n",
        "\n",
        "    **åš´æ ¼è¦æ±‚ï¼šä½ æå–çš„å…§å®¹ï¼Œå°¤å…¶æ˜¯ã€Œèª²ç¨‹åç¨±ã€å’Œã€Œåœ°é»ã€ï¼Œå¿…é ˆå®Œå…¨å­˜åœ¨æ–¼ PDF æ–‡ä»¶ä¸­ï¼Œä¸å¾—é€²è¡Œä»»ä½•æ¨æ¸¬ã€å‰µé€ ã€ç¾åŒ–æˆ–æ›´æ”¹ã€‚**\n",
        "\n",
        "    **è«‹åª**å¹«æˆ‘æ“·å–æ—¥æœŸç¯„åœåœ¨ **{start_date_str} åˆ° {end_date_str}** ä¹‹é–“çš„èª²è¡¨ç´€éŒ„ã€‚\n",
        "\n",
        "    ä½ çš„è¼¸å‡º**å¿…é ˆ**æ˜¯ CSV æ ¼å¼ï¼Œä¸¦ä¸”**åª**è¼¸å‡º CSV å…§å®¹ (åŒ…å«æ¨™é ­)ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–èªªæ˜æ–‡å­—ã€‚\n",
        "    CSV æ ¼å¼çš„æ¬„ä½å¿…é ˆå¦‚ä¸‹ï¼š\n",
        "    \"{csv_header}\"\n",
        "\n",
        "    - **é—œéµæŒ‡ä»¤ï¼š** å¦‚æœåŒä¸€å¤©æœ‰**å®Œå…¨ç›¸åŒèª²ç¨‹åç¨±å’Œåœ°é»**çš„èª²å ‚æ™‚æ®µæ˜¯**é€£çºŒçš„**ï¼Œè«‹å‹™å¿…å°‡å®ƒå€‘**åˆä½µæˆä¸€è¡Œç´€éŒ„**ï¼Œä½¿ç”¨**ç¬¬ä¸€å ‚èª²çš„é–‹å§‹æ™‚é–“**å’Œ**æœ€å¾Œä¸€å ‚èª²çš„çµæŸæ™‚é–“**ã€‚**è«‹åš´æ ¼ç¢ºä¿ï¼Œæ‰€æœ‰èª²å ‚çš„èª²ç¨‹åç¨±å¿…é ˆèˆ‡ PDF ä¸­çš„æ–‡å­—å®Œå…¨ä¸€æ¨£ï¼Œä¸å¾—ç°¡å¯«ã€çœç•¥æ‹¬è™Ÿæˆ–ä»»ä½•å­—å…ƒ**\n",
        "    - ã€Œ{helper_cols}ã€å’Œã€Œå‚™è¨»ã€é€™å¹¾æ¬„è«‹ä¿æŒç©ºç™½ï¼Œä¸è¦æœ‰ä»»ä½•æ¨™é»ç¬¦è™Ÿã€‚\n",
        "    - ã€Œæ—¥æœŸã€è«‹ä½¿ç”¨ YYYY/MM/DD æ ¼å¼ã€‚\n",
        "    \"\"\"\n",
        "\n",
        "    gemini_file = None\n",
        "    try:\n",
        "        gemini_file = genai.upload_file(path=pdf_path, display_name=\"Gradio Uploaded Schedule PDF\")\n",
        "        response = model.generate_content([prompt_text, gemini_file])\n",
        "        csv_output = response.text.strip()\n",
        "        if csv_output.startswith(\"```csv\"):\n",
        "             csv_output = csv_output.replace(\"```csv\\n\", \"\").replace(\"```\", \"\")\n",
        "\n",
        "        temp_csv_file = f\"gemini_schedule_{worksheet_name}.csv\"\n",
        "        with open(temp_csv_file, \"w\", encoding='utf-8') as f:\n",
        "            f.write(csv_output)\n",
        "\n",
        "        try:\n",
        "            try:\n",
        "                df_to_upload = pd.read_csv(temp_csv_file, engine='python', on_bad_lines='skip', sep=',', quotechar='\"')\n",
        "            except Exception:\n",
        "                df_to_upload = pd.read_csv(temp_csv_file, engine='python', on_bad_lines='skip', sep=',', quotechar='\"', skiprows=1, names=column_structure)\n",
        "\n",
        "            df_to_upload = df_to_upload.dropna(how='all')\n",
        "            df_to_upload = df_to_upload.fillna('')\n",
        "\n",
        "            for col in [\"æ—¥æœŸ\", \"èª²ç¨‹åç¨±\", \"åœ°é»\"]:\n",
        "                if col not in df_to_upload.columns:\n",
        "                    raise KeyError(f\"âŒ åš´é‡éŒ¯èª¤ï¼šCSV ä¸­ç¼ºå°‘å¿…è¦çš„æ¬„ä½ '{col}'ã€‚\")\n",
        "\n",
        "            helper_cols_to_clear = [c for c in column_structure if c not in COMMON_COLS and c != \"å‚™è¨»\"]\n",
        "            for col in helper_cols_to_clear:\n",
        "                if col in df_to_upload.columns:\n",
        "                    df_to_upload[col] = ''\n",
        "\n",
        "            def simplify_course_name(name):\n",
        "                name = re.sub(r'\\(.*?\\)', '', name)\n",
        "                name = re.sub(r'ï¼ˆ.*?ï¼‰', '', name)\n",
        "                return name.strip()\n",
        "\n",
        "            df_to_upload['èª²ç¨‹åç¨±_GROUP'] = df_to_upload['èª²ç¨‹åç¨±'].apply(simplify_course_name)\n",
        "\n",
        "            current_GROUP_KEYS = [\"æ—¥æœŸ\", \"èª²ç¨‹åç¨±\", \"åœ°é»\"]\n",
        "            columns_to_keep_first = [c for c in column_structure if c not in [\"æ™‚é–“(èµ·)\", \"æ™‚é–“(è¿„)\"]]\n",
        "            agg_rules = {col: 'first' for col in column_structure if col not in current_GROUP_KEYS}\n",
        "            agg_rules['æ™‚é–“(èµ·)'] = 'min'\n",
        "            agg_rules['æ™‚é–“(è¿„)'] = 'max'\n",
        "\n",
        "            df_merged = df_to_upload.groupby(current_GROUP_KEYS, as_index=False).agg(agg_rules)\n",
        "            df_merged = df_merged.drop(columns=['èª²ç¨‹åç¨±_GROUP'], errors='ignore')\n",
        "            df_to_upload = df_merged[column_structure]\n",
        "            print(f\"âœ… Pandas å·²å°‡æ™‚æ®µå¼·åˆ¶åˆä½µï¼Œæœ€çµ‚å¯«å…¥è³‡æ–™å…± {len(df_to_upload)} ç­†ã€‚\")\n",
        "\n",
        "            df_to_upload = df_to_upload.sort_values(by=['æ—¥æœŸ', 'æ™‚é–“(èµ·)'], ascending=True)\n",
        "\n",
        "            print(f\"âœ… æ•¸æ“šå·²æŒ‰æ—¥æœŸå’Œæ™‚é–“æ’åºå®Œæˆã€‚\")\n",
        "\n",
        "            gsheets = gc.open_by_url(SHEET_URL)\n",
        "            try:\n",
        "                worksheet = gsheets.worksheet(worksheet_name)\n",
        "            except gspread.exceptions.WorksheetNotFound:\n",
        "                worksheet = gsheets.add_worksheet(title=worksheet_name, rows=len(df_to_upload)+50, cols=len(df_to_upload.columns)+5)\n",
        "\n",
        "            data_to_write = [df_to_upload.columns.values.tolist()] + df_to_upload.values.tolist()\n",
        "            worksheet.clear()\n",
        "            worksheet.update(data_to_write)\n",
        "\n",
        "            success_msg = f\"âœ… æˆåŠŸå°‡èª²è¡¨å…§å®¹å¯«å…¥è‡³ '{worksheet_name}' åˆ†é ï¼\"\n",
        "            print(success_msg)\n",
        "\n",
        "            return df_to_upload, success_msg\n",
        "\n",
        "        except Exception as e:\n",
        "            err_msg = f\"âŒ è™•ç† CSV æˆ–å¯«å…¥ Sheets ç™¼ç”ŸéŒ¯èª¤ï¼š{e}\"\n",
        "            print(err_msg)\n",
        "            return pd.DataFrame(columns=column_structure), err_msg\n",
        "\n",
        "    except Exception as e:\n",
        "        err_msg = f\"âŒ Gemini èª²è¡¨ç”Ÿæˆç™¼ç”ŸéŒ¯èª¤ï¼š{e}\"\n",
        "        print(err_msg)\n",
        "        return pd.DataFrame(columns=column_structure), err_msg\n",
        "\n",
        "    finally:\n",
        "        if gemini_file:\n",
        "            genai.delete_file(gemini_file.name)\n",
        "            print(\"âœ… Gemini æª”æ¡ˆå·²æ¸…ç†ã€‚\")"
      ],
      "metadata": {
        "id": "RmWctw35ith5"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_pdf_upload(pdf_file_obj):\n",
        "    if pdf_file_obj is None:\n",
        "        return \"âš ï¸ è«‹å…ˆä¸Šå‚³ PDF æª”æ¡ˆã€‚\", pd.DataFrame(), pd.DataFrame(), pd.DataFrame() # message, preview, df_all, df_current, df_next\n",
        "\n",
        "    pdf_path = pdf_file_obj.name\n",
        "    message = f\"âœ… æˆåŠŸæ¥æ”¶æª”æ¡ˆ: '{os.path.basename(pdf_path)}'ã€‚é–‹å§‹è™•ç†...\\n\"\n",
        "\n",
        "    all_data_frames = []\n",
        "    messages = []\n",
        "    final_message = \"\"\n",
        "\n",
        "    df_current_week, msg_current = process_week_with_gemini(\n",
        "        START_DATE_CURRENT, END_DATE_CURRENT, WORKSHEET_NAME_CURRENT, COLUMNS_CURRENT, pdf_path\n",
        "    )\n",
        "\n",
        "    df_current_week = standardize_df(df_current_week, COLUMNS_CURRENT)\n",
        "    all_data_frames.append(df_current_week)\n",
        "    messages.append(msg_current)\n",
        "\n",
        "    df_next_week, msg_next = process_week_with_gemini(\n",
        "        START_DATE_NEXT, END_DATE_NEXT, WORKSHEET_NAME_NEXT, COLUMNS_NEXT, pdf_path\n",
        "    )\n",
        "    df_next_week = standardize_df(df_next_week, COLUMNS_NEXT)\n",
        "    all_data_frames.append(df_next_week)\n",
        "    messages.append(msg_next)\n",
        "\n",
        "    df_all_new = pd.concat([d for d in all_data_frames if not d.empty], ignore_index=True)\n",
        "\n",
        "    preview_df = pd.concat([df_current_week[COMMON_COLS], df_next_week[COMMON_COLS]], ignore_index=True)\n",
        "    if preview_df.empty:\n",
        "        final_message = \"âŒ è™•ç†å¤±æ•—ï¼Œæœªèƒ½å¾ PDF ä¸­æå–ä»»ä½•èª²è¡¨è³‡è¨Šã€‚\"\n",
        "    else:\n",
        "        final_message = \"\\n\".join(messages)\n",
        "\n",
        "    return final_message, preview_df, df_all_new, df_current_week, df_next_week\n",
        "\n",
        "\n",
        "# æŸ¥è©¢æŒ‡å®šæ—¥æœŸèª²ç¨‹\n",
        "def query_schedule(selected_date_label, df_current_state, df_next_state):\n",
        "\n",
        "    selected_date_str = DATE_OPTIONS.get(selected_date_label, today.strftime(\"%Y-%m-%d\"))\n",
        "\n",
        "    if gc is None:\n",
        "        return pd.DataFrame(columns=[\"èª²ç¨‹åç¨±\", \"æ™‚æ®µ\", \"ä½œæ¥­/æ”œå¸¶å“\", \"è¤‡ç¿’/é ç¿’ç« ç¯€\", \"å‚™è¨»\"]), \"âŒ éŒ¯èª¤ï¼šGoogle Sheets æœå‹™æœªæˆæ¬Šã€‚\", pd.DataFrame(), None\n",
        "\n",
        "    try:\n",
        "        target_date = dt_class.strptime(selected_date_str, \"%Y-%m-%d\").date()\n",
        "    except ValueError:\n",
        "        return pd.DataFrame(columns=[\"èª²ç¨‹åç¨±\", \"æ™‚æ®µ\", \"ä½œæ¥­/æ”œå¸¶å“\", \"è¤‡ç¿’/é ç¿’ç« ç¯€\", \"å‚™è¨»\"]), \"âŒ æ—¥æœŸæ ¼å¼éŒ¯èª¤ã€‚\", pd.DataFrame(), None\n",
        "\n",
        "    is_current_week = (START_DATE_CURRENT <= target_date <= END_DATE_CURRENT)\n",
        "    is_next_week = (START_DATE_NEXT <= target_date <= END_DATE_NEXT)\n",
        "\n",
        "    df_current = standardize_df(load_sheet_to_df(WORKSHEET_NAME_CURRENT), COLUMNS_CURRENT)\n",
        "    df_next = standardize_df(load_sheet_to_df(WORKSHEET_NAME_NEXT), COLUMNS_NEXT)\n",
        "\n",
        "    target_df = pd.DataFrame()\n",
        "    week_type = None\n",
        "\n",
        "    if is_current_week and not df_current.empty:\n",
        "        target_df = df_current[df_current[\"æ—¥æœŸ\"] == target_date].copy().sort_values([\"æ™‚é–“(èµ·)\"])\n",
        "        week_type = WORKSHEET_NAME_CURRENT\n",
        "    elif is_next_week and not df_next.empty:\n",
        "        target_df = df_next[df_next[\"æ—¥æœŸ\"] == target_date].copy().sort_values([\"æ™‚é–“(èµ·)\"])\n",
        "        week_type = WORKSHEET_NAME_NEXT\n",
        "\n",
        "    if target_df.empty:\n",
        "        return pd.DataFrame(columns=[\"èª²ç¨‹åç¨±\", \"æ™‚æ®µ\", \"ä½œæ¥­/æ”œå¸¶å“\", \"è¤‡ç¿’/é ç¿’ç« ç¯€\", \"å‚™è¨»\"]), \\\n",
        "               f\"ğŸ” {selected_date_str} ç„¡èª²ã€‚\", \\\n",
        "               pd.DataFrame(), None\n",
        "\n",
        "    if week_type == WORKSHEET_NAME_CURRENT:\n",
        "        col1_name, col2_name = \"ä½œæ¥­\", \"è¤‡ç¿’ç« ç¯€\"\n",
        "        input_col1_name, input_col2_name = \"ä½œæ¥­/æ”œå¸¶å“\", \"è¤‡ç¿’/é ç¿’ç« ç¯€)\"\n",
        "    else:\n",
        "        col1_name, col2_name = \"æ‡‰å¸¶ç”¨å“\", \"é ç¿’ç« ç¯€\"\n",
        "        input_col1_name, input_col2_name = \"ä½œæ¥­/æ”œå¸¶å“\", \"è¤‡ç¿’/é ç¿’ç« ç¯€\"\n",
        "\n",
        "    display_df = pd.DataFrame()\n",
        "    display_df[\"èª²ç¨‹åç¨±\"] = target_df[\"èª²ç¨‹åç¨±\"]\n",
        "    display_df[\"æ™‚æ®µ\"] = target_df[\"æ™‚é–“(èµ·)\"] + \"-\" + target_df[\"æ™‚é–“(è¿„)\"]\n",
        "    display_df[\"ä½œæ¥­/æ”œå¸¶å“\"] = target_df.get(col1_name, '')\n",
        "    display_df[\"è¤‡ç¿’/é ç¿’ç« ç¯€\"] = target_df.get(col2_name, '')\n",
        "    display_df[\"å‚™è¨»\"] = target_df.get(\"å‚™è¨»\", '')\n",
        "\n",
        "    df_input_to_save = target_df.copy()\n",
        "\n",
        "    return display_df, f\"âœ… æˆåŠŸæŸ¥è©¢ {selected_date_str} ({week_type}) èª²ç¨‹ã€‚\", df_input_to_save, week_type\n",
        "\n",
        "# å›å¯«å‚™è¨»åˆ° Sheets\n",
        "def write_back_schedule(edited_df, df_input_to_save, week_type):\n",
        "    default_df_return = (pd.DataFrame(), pd.DataFrame(), pd.DataFrame())\n",
        "\n",
        "    if df_input_to_save.empty or not week_type:\n",
        "        return \"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°ç•¶æ—¥èª²ç¨‹æˆ–å‚™è¨»è³‡è¨Šã€‚è«‹å…ˆæŸ¥è©¢èª²ç¨‹ä¸¦ç·¨è¼¯è¡¨æ ¼ã€‚\", *default_df_return\n",
        "\n",
        "    TARGET_SHEET_NAME = week_type\n",
        "\n",
        "    try:\n",
        "        wk = gc.open_by_url(SHEET_URL)\n",
        "        wk_sheet = wk.worksheet(TARGET_SHEET_NAME)\n",
        "        all_values = wk_sheet.get_all_values()\n",
        "        header = all_values[0]\n",
        "        data_df = pd.DataFrame(all_values[1:], columns=header)\n",
        "    except Exception as e:\n",
        "        return f\"âŒ è®€å– Google Sheets ç™¼ç”ŸéŒ¯èª¤ï¼š{e}\", *default_df_return\n",
        "\n",
        "    try:\n",
        "        if TARGET_SHEET_NAME == WORKSHEET_NAME_CURRENT:\n",
        "            col1_name, col2_name = \"ä½œæ¥­\", \"è¤‡ç¿’ç« ç¯€\"\n",
        "        else:\n",
        "            col1_name, col2_name = \"æ‡‰å¸¶ç”¨å“\", \"é ç¿’ç« ç¯€\"\n",
        "\n",
        "        col1_index = header.index(col1_name) + 1\n",
        "        col2_index = header.index(col2_name) + 1\n",
        "        col_å‚™è¨»_index = header.index(\"å‚™è¨»\") + 1\n",
        "    except ValueError:\n",
        "        return f\"### âŒ éŒ¯èª¤ï¼šåˆ†é  '{TARGET_SHEET_NAME}' ç¼ºå°‘å¿…è¦çš„æ¬„ä½ã€‚\", *default_df_return\n",
        "\n",
        "    updates = []\n",
        "\n",
        "    if len(edited_df) != len(df_input_to_save):\n",
        "        return \"âŒ éŒ¯èª¤ï¼šç·¨è¼¯çš„è¡Œæ•¸èˆ‡åŸå§‹æŸ¥è©¢çµæœä¸åŒ¹é…ï¼Œç„¡æ³•å›å¯«ã€‚\", *default_df_return\n",
        "\n",
        "    edited_df_dict = edited_df.set_index('èª²ç¨‹åç¨±').to_dict('index')\n",
        "\n",
        "    for _, input_row in df_input_to_save.iterrows():\n",
        "        match_course = input_row['èª²ç¨‹åç¨±']\n",
        "\n",
        "        edited_row = edited_df[edited_df['èª²ç¨‹åç¨±'] == match_course].iloc[0]\n",
        "\n",
        "        new_col1_value = str(edited_row[\"ä½œæ¥­/æ”œå¸¶å“\"]).strip()\n",
        "        new_col2_value = str(edited_row[\"è¤‡ç¿’/é ç¿’ç« ç¯€\"]).strip()\n",
        "        new_å‚™è¨» = str(edited_row['å‚™è¨»']).strip()\n",
        "\n",
        "        match_date = str(input_row['æ—¥æœŸ'])\n",
        "\n",
        "        for row_index, sheet_row in enumerate(data_df.values.tolist()):\n",
        "            raw_sheet_date = sheet_row[header.index(\"æ—¥æœŸ\")]\n",
        "            sheet_course = sheet_row[header.index(\"èª²ç¨‹åç¨±\")]\n",
        "\n",
        "            normalized_sheet_date = raw_sheet_date.replace(\"/\", \"-\")\n",
        "\n",
        "            if normalized_sheet_date == match_date and sheet_course == match_course:\n",
        "                actual_row_num = row_index + 2\n",
        "\n",
        "                if new_col1_value:\n",
        "                    updates.append({'range': gspread.utils.rowcol_to_a1(actual_row_num, col1_index), 'values': [[new_col1_value]]})\n",
        "                if new_col2_value:\n",
        "                    updates.append({'range': gspread.utils.rowcol_to_a1(actual_row_num, col2_index), 'values': [[new_col2_value]]})\n",
        "                if new_å‚™è¨»:\n",
        "                    updates.append({'range': gspread.utils.rowcol_to_a1(actual_row_num, col_å‚™è¨»_index), 'values': [[new_å‚™è¨»]]})\n",
        "\n",
        "                break\n",
        "\n",
        "    if updates:\n",
        "        wk_sheet.batch_update(updates)\n",
        "        msg = f\"âœ… æˆåŠŸæ›´æ–° {len(updates)} å€‹å–®å…ƒæ ¼åˆ° **'{TARGET_SHEET_NAME}'** åˆ†é ä¸­ã€‚\"\n",
        "    else:\n",
        "        msg = \"â„¹ï¸ æ²’æœ‰æ‰‹å‹•è¼¸å…¥çš„å‚™è¨»éœ€è¦æ›´æ–°åˆ° Sheets ä¸­ã€‚\"\n",
        "\n",
        "    df_all_new, df_current_new, df_next_new = initial_data_load()\n",
        "\n",
        "    return msg, df_all_new, df_current_new, df_next_new"
      ],
      "metadata": {
        "id": "cX2vR9FKi-gT"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_one_line_reminder(rows, is_current_week):\n",
        "    if rows.empty: return \"\"\n",
        "\n",
        "    r = rows.iloc[0]\n",
        "    date_str = str(r.get(\"æ—¥æœŸ\", \"\")).strip().replace(\"/\", \"-\")\n",
        "    weekday = str(r.get(\"æ˜ŸæœŸ\", \"\")).strip()\n",
        "    course_name = str(r.get(\"èª²ç¨‹åç¨±\", \"\")).strip()\n",
        "\n",
        "    if is_current_week:\n",
        "        item_col = \"ä½œæ¥­\"\n",
        "        read_col = \"è¤‡ç¿’ç« ç¯€\"\n",
        "        item_label = \"ä½œæ¥­\"\n",
        "        read_label = \"è¤‡ç¿’ç« ç¯€\"\n",
        "    else:\n",
        "        item_col = \"æ‡‰å¸¶ç”¨å“\"\n",
        "        read_col = \"é ç¿’ç« ç¯€\"\n",
        "        item_label = \"æ”œå¸¶å“\"\n",
        "        read_label = \"é ç¿’ç« ç¯€\"\n",
        "\n",
        "    item_value = str(r.get(item_col, '')).strip()\n",
        "    read_value = str(r.get(read_col, '')).strip()\n",
        "    memo_value = str(r.get(\"å‚™è¨»\", '')).strip()\n",
        "\n",
        "    item_output = f\"{item_label}ï¼š{item_value if item_value else 'ç„¡'}\"\n",
        "    read_output = f\"{read_label}ï¼š{read_value if read_value else 'ç„¡'}\"\n",
        "    memo_output = f\"å‚™è¨»ï¼š{memo_value if memo_value else 'ç„¡'}\"\n",
        "\n",
        "    return f\"{date_str} {weekday} {course_name} {item_output} {read_output} {memo_output}\"\n",
        "\n",
        "# ç”Ÿæˆæé†’èˆ‡ AI è³‡æº\n",
        "def generate_reminder_and_ai_resources(selected_date_label, df_current, df_next):\n",
        "    if model is None:\n",
        "        return \"âŒ éŒ¯èª¤ï¼šGemini API æœªé…ç½®ï¼Œç„¡æ³•ç”Ÿæˆ AI å…§å®¹ã€‚\", \"âŒ éŒ¯èª¤ï¼šGemini API æœªé…ç½®ï¼Œç„¡æ³•ç”Ÿæˆ AI å…§å®¹ã€‚\"\n",
        "\n",
        "    selected_date_str = DATE_OPTIONS.get(selected_date_label, dt_class.now(TW_TZ).date().strftime(\"%Y-%m-%d\"))\n",
        "\n",
        "    try:\n",
        "        target_date = dt_class.strptime(selected_date_str, \"%Y-%m-%d\").date()\n",
        "    except ValueError:\n",
        "        return \"âŒ æ—¥æœŸæ ¼å¼éŒ¯èª¤ã€‚\", \"âŒ æ—¥æœŸæ ¼å¼éŒ¯èª¤ã€‚\"\n",
        "\n",
        "    is_current_week = (START_DATE_CURRENT <= target_date <= END_DATE_CURRENT)\n",
        "    is_next_week = (START_DATE_NEXT <= target_date <= END_DATE_NEXT)\n",
        "\n",
        "    if is_current_week and not df_current.empty:\n",
        "        target_df = df_current[df_current[\"æ—¥æœŸ\"] == target_date].copy().sort_values([\"æ™‚é–“(èµ·)\"])\n",
        "        week_type = WORKSHEET_NAME_CURRENT\n",
        "    elif is_next_week and not df_next.empty:\n",
        "        target_df = df_next[df_next[\"æ—¥æœŸ\"] == target_date].copy().sort_values([\"æ™‚é–“(èµ·)\"])\n",
        "        week_type = WORKSHEET_NAME_NEXT\n",
        "    else:\n",
        "        return f\"ğŸ” {selected_date_str} ä¸åœ¨ç›®å‰èª²è¡¨ç¯„åœå…§æˆ–èª²è¡¨ç‚ºç©ºã€‚\", \"â„¹ï¸ ç„¡æ³•ç”Ÿæˆè³‡æºæ¨è–¦ã€‚\"\n",
        "\n",
        "    if target_df.empty:\n",
        "        return f\"ğŸ” {selected_date_str} ç„¡èª²ï¼Œä¸éœ€æº–å‚™ã€‚\", \"â„¹ï¸ ä»Šæ—¥ç„¡èª²ç¨‹ï¼Œç„¡éœ€æ¨è–¦è³‡æºã€‚\"\n",
        "\n",
        "    reminders = []\n",
        "    for _, row in target_df.iterrows():\n",
        "        single_course_df = pd.DataFrame([row])\n",
        "        one_line = make_one_line_reminder(single_course_df, is_current_week)\n",
        "        if one_line:\n",
        "            reminders.append(one_line)\n",
        "\n",
        "    reminder_output_text = \"ä»Šæ—¥ç„¡èª²ç¨‹æˆ–æ•¸æ“šéŒ¯èª¤ã€‚\"\n",
        "    if reminders:\n",
        "        reminder_output_text = f\"#### ğŸ“ æœ€çµ‚è¡Œå‰æé†’ï¼ˆ{week_type}ï¼‰\\n\" + \"\\n\".join([f\"- {r}\" for r in reminders])\n",
        "\n",
        "    ai_recommendation_text = \"### ğŸ’¡ AI èª²ç¨‹è³‡æºæ¨è–¦\\n\"\n",
        "    course_list = target_df['èª²ç¨‹åç¨±'].unique().tolist()\n",
        "\n",
        "    for course in course_list:\n",
        "        try:\n",
        "            prompt = f\"\"\"\n",
        "            è«‹ä½¿ç”¨ **google:search** å·¥å…·æŸ¥æ‰¾ä¸¦ç‚ºèª²ç¨‹ \"{course}\" æä¾›ä¸€å€‹å…·é«”çš„å­¸ç¿’è³‡æºæ¨è–¦ã€‚\n",
        "\n",
        "            æ¨è–¦çš„å…§å®¹å¿…é ˆåŒ…å«ä»¥ä¸‹å…©é»ï¼š\n",
        "            1. ä¸€å€‹ç›¸é—œçš„ **YouTube å½±ç‰‡é€£çµ** (éœ€åŒ…å«å½±ç‰‡æ¨™é¡Œ)ã€‚\n",
        "            2. ä¸€å€‹ç›¸é—œçš„ **å»¶ä¼¸é–±è®€æ–‡ç« /ç¶²ç«™é€£çµ** (éœ€åŒ…å«æ–‡ç« /ç¶²ç«™æ¨™é¡Œ)ã€‚\n",
        "\n",
        "            è«‹ä»¥ä»¥ä¸‹ Markdown æ ¼å¼è¼¸å‡ºï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–æ–‡å­—èªªæ˜ï¼š\n",
        "\n",
        "            #### ğŸ“š ã€{course}ã€‘ æ¨è–¦è³‡æº\n",
        "\n",
        "            **YouTube æ¨è–¦**\n",
        "            - [å½±ç‰‡æ¨™é¡Œ](å½±ç‰‡é€£çµ)\n",
        "\n",
        "            **å»¶ä¼¸é–±è®€**\n",
        "            - [æ–‡ç« /ç¶²ç«™æ¨™é¡Œ](æ–‡ç« /ç¶²ç«™é€£çµ)\n",
        "            \"\"\"\n",
        "            response = model.generate_content(prompt)\n",
        "\n",
        "            ai_recommendation_text += response.text.strip() + \"\\n\\n---\\n\"\n",
        "\n",
        "        except Exception as e:\n",
        "            ai_recommendation_text += f\"#### ğŸ“š ã€{course}ã€‘ æ¨è–¦è³‡æº\\næŸ¥æ‰¾å¤±æ•—: {e}\\n\\n---\\n\"\n",
        "\n",
        "    return reminder_output_text, ai_recommendation_text"
      ],
      "metadata": {
        "id": "Jn6AROnajQaT"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_df_all, initial_df_current, initial_df_next = initial_data_load()\n",
        "initial_df_input_to_save = pd.DataFrame()\n",
        "initial_week_type = None\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ğŸ—“ï¸ èª²è¡¨ç®¡ç†èˆ‡è¡Œå‰æé†’ç³»çµ±\")\n",
        "\n",
        "    df_all_state = gr.State(initial_df_all)\n",
        "    df_current_state = gr.State(initial_df_current)\n",
        "    df_next_state = gr.State(initial_df_next)\n",
        "    df_input_to_save_state = gr.State(initial_df_input_to_save)\n",
        "    week_type_state = gr.State(initial_week_type)\n",
        "\n",
        "    with gr.Tab(\"ğŸ”„ èª²è¡¨æ›´æ–°èˆ‡ PDF ä¸Šå‚³\"):\n",
        "        gr.Markdown(\"### ä¸Šå‚³æ–° PDF èª²è¡¨ä¸¦æ›´æ–° Sheets åˆ†é \")\n",
        "\n",
        "        with gr.Row():\n",
        "            pdf_uploader = gr.File(\n",
        "                label=\"ä¸Šå‚³æ‚¨çš„æ–° PDF èª²è¡¨æª”æ¡ˆ\",\n",
        "                file_types=[\".pdf\"],\n",
        "                scale=2\n",
        "            )\n",
        "\n",
        "        upload_button = gr.Button(\"ğŸš€ æå–èª²è¡¨ä¸¦å›å¯« Sheets (è‡ªå‹•æ›´æ–°æœ¬é€±èˆ‡ä¸‹é€±)\", variant=\"primary\")\n",
        "\n",
        "        upload_message = gr.Textbox(label=\"è™•ç†çµæœå°‡é¡¯ç¤ºæ–¼æ­¤\", lines=3, interactive=False)\n",
        "\n",
        "        gr.Markdown(\"#### æˆåŠŸæå–çš„æ•¸æ“šé è¦½\")\n",
        "        preview_df = gr.Dataframe(\n",
        "            value=pd.DataFrame(columns=COMMON_COLS),\n",
        "            label=\"æå–çš„æ•¸æ“šé è¦½\",\n",
        "            interactive=False\n",
        "        )\n",
        "\n",
        "        upload_button.click(\n",
        "            handle_pdf_upload,\n",
        "            inputs=[pdf_uploader],\n",
        "            outputs=[upload_message, preview_df, df_all_state, df_current_state, df_next_state]\n",
        "        )\n",
        "\n",
        "\n",
        "    with gr.Tab(\"ğŸ“ èª²ç¨‹å‚™è¨»èˆ‡å›å¯«\"):\n",
        "        gr.Markdown(\"### æŸ¥è©¢èª²ç¨‹ä¸¦è¼¸å…¥å‚™è¨»\")\n",
        "\n",
        "        with gr.Row():\n",
        "            date_selector = gr.Dropdown(\n",
        "                label=\"é¸æ“‡æ‚¨è¦æŸ¥è©¢çš„æ—¥æœŸ\",\n",
        "                choices=list(DATE_OPTIONS.keys()),\n",
        "                value=list(DATE_OPTIONS.keys())[0],\n",
        "                interactive=True,\n",
        "                scale=1\n",
        "            )\n",
        "\n",
        "        output_df = gr.DataFrame(\n",
        "            value=pd.DataFrame(columns=[\"èª²ç¨‹åç¨±\", \"æ™‚æ®µ\", \"ä½œæ¥­/æ”œå¸¶å“\", \"è¤‡ç¿’/é ç¿’ç« ç¯€\", \"å‚™è¨»\"]),\n",
        "            headers=[\"èª²ç¨‹åç¨±\", \"æ™‚æ®µ\", \"ä½œæ¥­/æ”œå¸¶å“\", \"è¤‡ç¿’/é ç¿’ç« ç¯€\", \"å‚™è¨»\"],\n",
        "            label=\"èª²ç¨‹åˆ—è¡¨èˆ‡è¼¸å…¥ (è«‹ç›´æ¥åœ¨è¡¨æ ¼ä¸­ç·¨è¼¯)\",\n",
        "            interactive=True,\n",
        "        )\n",
        "\n",
        "        with gr.Row():\n",
        "            query_button = gr.Button(\"ğŸ” æŸ¥è©¢ç•¶æ—¥èª²ç¨‹ (æ›´æ–°è¡¨æ ¼)\", scale=1)\n",
        "            write_back_button = gr.Button(\"ğŸ’¾ å°‡å‚™è¨»å›å¯«åˆ° Google Sheets\", variant=\"primary\", scale=1)\n",
        "\n",
        "        write_back_output = gr.Textbox(label=\"å›å¯« Sheets çµæœ\", lines=3, interactive=False)\n",
        "\n",
        "        query_button.click(\n",
        "            query_schedule,\n",
        "            inputs=[date_selector, df_current_state, df_next_state],\n",
        "            outputs=[output_df, write_back_output, df_input_to_save_state, week_type_state]\n",
        "        )\n",
        "\n",
        "        write_back_button.click(\n",
        "            write_back_schedule,\n",
        "            inputs=[output_df, df_input_to_save_state, week_type_state],\n",
        "            outputs=[write_back_output]\n",
        "        )\n",
        "\n",
        "\n",
        "    with gr.Tab(\"ğŸ’¡ AI èª²ç¨‹è³‡æºæ¨è–¦\"):\n",
        "        gr.Markdown(\"### ç”Ÿæˆè¡Œå‰æé†’èˆ‡ AI æ¨è–¦è³‡æº\")\n",
        "\n",
        "        with gr.Row():\n",
        "            date_selector_ai = gr.Dropdown(\n",
        "                label=\"é¸æ“‡æ—¥æœŸ (èˆ‡å‚™è¨»åˆ†é åŒæ­¥)\",\n",
        "                choices=list(DATE_OPTIONS.keys()),\n",
        "                value=list(DATE_OPTIONS.keys())[0],\n",
        "                interactive=True,\n",
        "                scale=1\n",
        "            )\n",
        "            ai_query_button = gr.Button(\"ğŸ§  ç”Ÿæˆæé†’èˆ‡ AI è³‡æºæ¨è–¦\", variant=\"secondary\", scale=1)\n",
        "\n",
        "        reminder_output = gr.Markdown(\"æœ€çµ‚è¡Œå‰æé†’å°‡é¡¯ç¤ºæ–¼æ­¤\", visible=True)\n",
        "        ai_output = gr.Markdown(\"AI èª²ç¨‹è³‡æºæ¨è–¦å°‡é¡¯ç¤ºæ–¼æ­¤\", visible=True)\n",
        "\n",
        "        ai_query_button.click(\n",
        "            generate_reminder_and_ai_resources,\n",
        "            inputs=[date_selector_ai, df_current_state, df_next_state],\n",
        "            outputs=[reminder_output, ai_output]\n",
        "        )"
      ],
      "metadata": {
        "id": "RpCGWe5kjaV5"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch(debug=True, share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "nFWM40ytjdyK",
        "outputId": "3690e616-46e3-43bd-fc60-d322fa6493af"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://d28576031735a58f48.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d28576031735a58f48.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://d28576031735a58f48.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    }
  ]
}